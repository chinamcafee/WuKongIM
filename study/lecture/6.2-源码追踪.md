# 6.2 源码追踪

> **本节目标**：逐行梳理消息发送链路的关键函数，掌握从网络入口到推送出站的全部源码跳转关系

---

## 📋 目录
1. [入口：handleAuthenticatedConn](#入口handleauthenticatedconn)
2. [用户层：handleOnSend 前置处理](#用户层handleonsend-前置处理)
3. [频道层：权限校验与伪频道](#频道层权限校验与伪频道)
4. [持久化：Raft 提案与 MessageSeq 回填](#持久化raft-提案与-messageseq-回填)
5. [分发：SendAck、Webhook 与 Push 事件](#分发sendackwebhook-与-push-事件)
6. [推送：在线写入与 RecvAck 回收](#推送在线写入与-recvack-回收)

---

## 1️⃣ 入口：handleAuthenticatedConn

### **A. 聚合帧并生成事件**

- **定位**：`internal/server/proto.go:73-167`
- 逻辑要点：
  - 从连接缓冲区一次性 `Peek`，循环解析成 `wkproto.Frame`
  - 每帧封装为 `eventbus.Event`，并初始化 `Track`。SEND 帧额外赋值 `MessageId`
  - 累积事件后调用 `eventbus.User.AddEvents(connCtx.Uid, events)`，统一推进

```go
for i, frame := range frames {
    event := &eventbus.Event{...
        Type: eventbus.EventOnSend,
        Frame: frame,
        Conn:  connCtx,
        MessageId: options.G.GenMessageId(),
    }
    event.Track.Record(track.PositionStart)
    events = append(events, event)
}
```

> 解析失败或非法帧会触发 `conn.Close()`，保证后续链路都建立在可信数据上。

---

## 2️⃣ 用户层：handleOnSend 前置处理

### **A. 入口函数**
- **定位**：`internal/user/handler/event_onsend.go:21`
- `onSend` 根据帧类型分派：SEND → `handleOnSend`，RECVACK → `recvack`，PING → 心跳处理

### **B. 关键步骤**

1. **伪频道映射**：个人/Agent 频道通过 `options.GetFakeChannelIDWith`、`GetAgentChannelIDWith` 绑定发送端，确保多端一致（`internal/user/handler/event_onsend.go:44-52`）
2. **全局封禁**：`checkGlobalSendPermission` 读取发送者个人频道信息，判断禁言/过期（`internal/user/handler/event_onsend.go:67-92`）
3. **端到端解密**：若未禁用加密且非 JSON-RPC，调用 `decryptPayload` 验证 MsgKey、解密 payload（`internal/user/handler/event_onsend.go:94-113`）
4. **插件链**：遍历 `PluginSend`，允许阻断或修改消息（`internal/user/handler/event_onsend.go:115-133`）
5. **统计**：`trace.GlobalTrace.Metrics.App()` 记录发送计数与字节
6. **投递频道事件**：

```go
eventbus.Channel.SendMessage(fakeChannelId, channelType, &eventbus.Event{
    Type:      eventbus.EventChannelOnSend,
    Conn:      conn,
    Frame:     sendPacket,
    MessageId: event.MessageId,
    Track:     event.Track,
    ReqId:     event.ReqId,
})
eventbus.Channel.Advance(fakeChannelId, channelType)
```

> 所有失败分支都会即时构造 `SendackPacket` 写回客户端，保证请求级幂等性。

---

## 3️⃣ 频道层：权限校验与伪频道

### **A. onSend 执行链**
- **定位**：`internal/channel/handler/event_onsend.go:8-17`
- 对同一批次事件依次执行：`permission` → `persist` → `sendack`

### **B. 权限校验细节**
- **定位**：`internal/channel/handler/event_permission.go:12-55`
- 流程：
  1. 记录 `track.PositionChannelPermission`
  2. 调用 `service.Permission.HasPermissionForChannel` 检查频道是否被封禁/解散
  3. 遍历事件，逐一执行 `HasPermissionForSender`
     - 个人频道：可能通过 RPC (`requestAllowSend`) 查询对端节点
     - 共用频道：校验黑名单 / 订阅关系 / 白名单
  4. 将原因码写回 `event.ReasonCode`，失败的消息不再进入后续流程

> 频道层处理的是“伪频道 ID”，因此黑名单、订阅、白名单查询都基于统一的 fake id，天然支持多端同步。

---

## 4️⃣ 持久化：Raft 提案与 MessageSeq 回填

### **A. toPersistMessages**
- **定位**：`internal/channel/handler/event_persist.go:154-187`
- 将事件转换为 `wkdb.Message`，复制 SendPacket 头结构，补充时间戳、FromUID

### **B. AppendMessages 调用链**
1. `service.Store.AppendMessages`（`internal/channel/handler/event_persist.go:34`）
2. `pkg/cluster/store/message.go:9-33` 将多条消息编码为 `types.ProposeReq`
3. `pkg/cluster/channel/iserver.go:14-63` 根据频道定位到 RaftGroup
4. `pkg/raft/raft/raft_propose.go:53-119` 执行 `ProposeBatchUntilAppliedTimeout`
   - 如果当前节点是 leader，先本地拼装日志，再等待 apply；否则转发到 leader 并监听 apply 完成

### **C. 回填与插件**
- 成功后遍历 `results`，填充 `event.MessageSeq`、`persists[i].MessageSeq`（`internal/channel/handler/event_persist.go:40-58`）
- 触发 `PluginPersistAfter`（`internal/channel/handler/event_persist.go:60-151`）
- 将 `ReasonCode` 写回事件，供 sendack/distribute 使用

> 这一段是消息“持久化成功”的唯一判定点，也是与 Raft 的交汇处。

---

## 5️⃣ 分发：SendAck、Webhook 与 Push 事件

### **A. SendAck 回执**
- **定位**：`internal/channel/handler/event_sendack.go:7-40`
- 针对非系统连接生成 `SendackPacket`，写回原连接，并对 UID 调用 `eventbus.User.Advance` 推进行程
- RedDot、ClientSeq 等字段都沿用原始 SendPacket 值

### **B. Webhook**
- `persist` 在成功分支中克隆事件为 `EventChannelWebhook`，重新写入 ChannelEventPool（`internal/channel/handler/event_persist.go:91-101`）
- `internal/channel/handler/event_webhook.go` 负责实际回调第三方系统

### **C. 分发至 Push**
- `cloneEvent.Type = eventbus.EventChannelDistribute`（`internal/channel/handler/event_persist.go:103-110`）
- `distribute`（`internal/channel/handler/event_distribute.go:19-188`）
  - 获取/创建标签 `Tag`，维护频道到节点/用户的映射
  - 将本地在线用户克隆为 `EventPushOnline`
  - 离线用户列表构造成 `EventPushOffline`，交由 webhook 或 AI 处理

---

## 6️⃣ 推送：在线写入与 RecvAck 回收

### **A. 在线推送**
- **定位**：`internal/pusher/handler/event_pushonline.go:20-165`
- 关键步骤：
  1. 获取目标 UID 的所有认证连接
  2. 为每个连接构建 `RecvPacket`（重新加密、生成 MsgKey、设置红点、StreamId 等）
  3. 调用 `service.RetryManager.AddRetry` 注册可靠消息（`internal/pusher/handler/event_pushonline.go:124-135`）
  4. `eventbus.User.ConnWrite` 将帧写入同 UID 的 UserEventPool，由用户层的 `writeFrame` 统一调度到 `wknet`

### **B. RecvAck 回收**
- **定位**：`internal/user/handler/event_recvack.go:19-71`
- 当客户端发送 RECVACK：
  - 记录轨迹 `track.PositionUserRecvack`
  - 使用 `service.RetryManager.RemoveRetry` 删除重试任务
  - 如满足条件，异步更新最近会话已读位点（`service.Store.UpdateConversationIfSeqGreaterAsync`）
  - 打印 Trace 日志辅助排查

### **C. 重试机制**
- `RetryManager`（`internal/manager/manager_retry.go:16-139`）
  - 将消息按 `messageId % workerCount` 分片放入 `RetryQueue`
  - 基于 `timingwheel` 定时重投 `eventbus.User.ConnWrite`
  - 超过重试上限打印警告，避免无限循环

> 至此，一条消息从发送端完成了网络入口 → 用户预处理 → 频道持久化 → 推送出站 → ACK 回收的完整闭环。

